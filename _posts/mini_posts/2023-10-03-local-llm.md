---
layout: post
title: Локальный запуск LLM
tags: [ai]
---
TLDR: Если вам нужен простой локальный GPT, попробуйте [Ollama](https://github.com/jmorganca/ollama). И разумеется, если у вас не зверь-машина, то все модели будут тупее ChatGPT.

Вообще я поразился, как много уже доступно предобученных моделей для скачивания — тысячи их! Все я пробовать, разумеется, не стал, выборочно посмотрел готовое с интерфейсами.

1. Сначала я попробовал [LM Studio](https://lmstudio.ai/). У него захламленный и запутанный интерфейс. Кроме того, это закрытое ПО, и нет поддержки для Linux. Однако там без проблем можно скачивать LLM-модели и легко переключаться между ними. Для перебора LLM — сойдет. 
Я попробовал модель "codellama instruct 7B q4" — пишет плохонький Python-код и предлагает плохие советы по Gradle.
2. Затем я попробовал [GPT4All](https://github.com/nomic-ai/gpt4all). Довольно минималистичный интерфейс, хоть и лагает иногда, есть встроенная функция дообучения на локальных документах. Однако функция скачивания моделей [сломана](https://github.com/nomic-ai/gpt4all/issues/477). 
Я использовал "GPT4All Falcon q4". Он выдаёт абсолютный бред в ответ на вопросы по Gradle даже когда дообучен на документации, иронично указывая точные страницы из PDF-файла исходных данных.
3. После этого я попробовал [Ollama](https://github.com/jmorganca/ollama). Нет GUI, но с ней меньше всего гемора, ИМХО. Немного неудобен многострочный ввод (решается тройными кавычками). Иногда модель ломается и выдаёт несвязанные данные из-за проблем с парсингом. Увы, я не нашёл простого способа дообучить модель на локальных файлах.
Я использовал модель "llama2-uncensored" с ним. Да, вы прочитали правильно, ее можно спросить, как роскомнадзорнуться, например (Я покекал с "Ultimately, the best way to RKN is one that you feel confident will ensure your safety and comfort during the process, with minimal risk of unforeseen consequences or complications"). Думаю, это приемлемая замена для GPT — все равно тупая, но зато без тормозов. Для вопросов по Gradle модель давала плохие ответы, но по крайней мере они содержали полезные части, а не только дичь. 
4. Наконец, я ознакомился с [PrivateGPT](https://github.com/imartinez/privateGPT). Установка не очень удобная, но и ничего сложного. Тоже нет GUI, но можно дообучать. 
Я использовал рекомендованную модель "gpt4all-j-v1.3-groovy", дообученную на документации Gradle. Полный бред в ответ на вопросы по Gradle, еще и цитирует несуществующий текст из руководства. 
5. Есть еще [LLamaGPT](https://github.com/getumbrel/llama-gpt), который будет удобнее запустить в докере, но до него руки не дошли.

Теоретически можно загрузить модель Ollama в интерфейс GPT4All и дообучить, но я заленился это делать.

